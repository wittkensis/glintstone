<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cuneiform Artifact Processing Pipeline Architecture</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
            background-color: #f4f4f4;
            color: #333;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        .section {
            background-color: #fff;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        pre {
            background-color: #eee;
            padding: 10px;
            border-radius: 4px;
            overflow-x: auto;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 20px;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
        }
        code {
            background-color: #f8f8f8;
            padding: 2px 4px;
            border-radius: 4px;
        }
        ul, ol {
            margin-left: 20px;
        }
    </style>
</head>
<body>

    <h1>Updated Architecture for Cuneiform Artifact Processing Pipeline</h1>

    <div class="section">
        <p>This updated architecture reframes the system as an "assembly line" pipeline for processing individual cuneiform artifacts (e.g., a clay tablet or inscription). Each artifact is treated as a single entity that progresses through sequential stages, with tools modifying or enriching it at specific points. The pipeline transforms raw inputs (e.g., images or scans) into fully translated, contextualized information.</p>

        <p>Central to this is a <strong>Single Source of Truth (SSoT)</strong> structure: a unified artifact record in a central repository (e.g., a graph database like Neo4j or a document store like MongoDB). The SSoT acts as the "master file" for each artifact, versioning its state as it moves through the pipeline. It ties all elements together by:</p>
        <ul>
            <li>Assigning a unique ID (e.g., based on CDLI or custom UUID).</li>
            <li>Storing progressive enrichments (e.g., raw image → transliteration → translation → context).</li>
            <li>Enabling traceability (e.g., audit logs of tool applications).</li>
            <li>Supporting queries across stages for a complete "artifact biography."</li>
        </ul>

        <p>The pipeline is platform-agnostic, implementable in workflows like Apache Airflow, AWS Step Functions, or custom scripts. It balances consumer-grade clarity (e.g., simple stage names like "Scan the Artifact") with academic rigor (e.g., precise data transformations).</p>
    </div>

    <div class="section">
        <h2>High-Level Pipeline Diagram (Markdown Representation)</h2>
        <pre>
[Raw Artifact Input] --> [Stage 1: Ingestion] --> [Stage 2: Digitization & Recognition] --> [Stage 3: Transliteration] --> [Stage 4: Translation] --> [Stage 5: Annotation & Enrichment] --> [Stage 6: Contextualization (New Layer)] --> [Stage 7: Output & Archiving] --> [SSoT Repository]

SSoT Repository (Central Hub):
- Artifact ID as Key
- Versioned States (e.g., v1: Raw → v2: Recognized → ... → vFinal: Contextualized)
- Links to External Resources (e.g., CDLI IDs, LOD URIs)
- Query Interface for "Grokipedia"-like Views

Tools Integration:
- Applied per Stage (Detailed Below)
- Artifact Flows Sequentially; Tools Modify In-Place (e.g., Add Fields to Artifact Object)
        </pre>
    </div>

    <div class="section">
        <h2>Pipeline Stages and Artifact Flow</h2>
        <p>The artifact starts as a raw input (e.g., an image file or URL) and evolves through stages. At each step:</p>
        <ul>
            <li>The artifact is an object (e.g., JSON document) with fields like <code>raw_image</code>, <code>recognized_symbols</code>, <code>transliteration</code>, etc.</li>
            <li>Tools update the object, then pass it to the next stage.</li>
            <li>If a stage fails (e.g., no relevant data), flag it in the SSoT and proceed with partial results.</li>
            <li>Parallelism: Some tools can run in sub-pipelines (e.g., multiple enrichments), but the main flow is linear for traceability.</li>
        </ul>

        <ol>
            <li>
                <h3>Stage 1: Ingestion (Acquire and Prepare Raw Artifact)</h3>
                <p><strong>Description</strong>: Intake the raw artifact (e.g., photo, scan, or ID from a database). Normalize basic metadata (e.g., file format, source).</p>
                <p><strong>Artifact Modification</strong>: Add initial fields like <code>artifact_id</code>, <code>raw_data</code> (e.g., image bytes or URL), <code>provenance</code> (basic source info).</p>
                <p><strong>Technical Implementation Details</strong>: This stage focuses on data acquisition and preprocessing. Use a workflow orchestrator (e.g., Airflow DAG) to trigger ingestion via API calls or file uploads. Handle inputs as streams to avoid memory issues for large files. Validate formats (e.g., check if image is PNG/JPG using libraries like Pillow in code execution). Store temporary files in a shared volume if needed for multi-tool access. For SSoT integration, use a database transaction to insert the initial version atomically.</p>
                <p><strong>Tools Mapping</strong> (Best Tools and Exact Usage):</p>
                <ul>
                    <li><strong>View Image</strong> (Best for visual inspection of image-based artifacts): Use this as the primary tool for loading and describing raw images. How: Call with the image URL or artifact identifier to retrieve a detailed description, which can be used to extract initial metadata such as estimated number of signs, script type, condition, etc. Integrate the output into the artifact JSON as <code>visual_description</code>.</li>
                    <li><strong>Search Images</strong> (Best for finding reference images): Use to locate similar artifacts or standard photos. How: Provide a description like “high-resolution Persepolis Fortification tablet” or “Ur III administrative tablet from Nippur” to get image URLs. Download selected images via code_execution and store them in <code>reference_images</code> array for later comparison or data augmentation.</li>
                    <li><strong>Search Pdf Attachment</strong> (Best if the raw input is a PDF document or museum catalog): Use to search within uploaded or linked PDFs. How: Query with keywords such as “cuneiform tablet P123456” or “Persepolis Fortification tablet PF 00123” to return relevant page numbers and text snippets. Then chain to browse_pdf_attachment.</li>
                    <li><strong>Browse Pdf Attachment</strong> (Best for extracting content from PDFs): Use after search_pdf_attachment. How: Specify exact pages (e.g., '1,3,5-7,12') to retrieve full text + screenshots. Parse the returned text for provenance, publication history, and any preliminary transliterations; store in <code>provenance_metadata</code>.</li>
                    <li><strong>Code Execution</strong> (Best for local file processing and standardization): Use to run Python code for preprocessing. How: 
                        <pre><code>from PIL import Image; img = Image.open('artifact.jpg'); img = img.convert('RGB'); img.save('standardized.png')</code></pre>
                        Extract EXIF/metadata: <code>img.info</code>. Resize/crop for recognition: <code>img.thumbnail((2048, 2048))</code>. Convert PDF pages to images if needed: use <code>pdf2image</code> library if available or fallback to Pillow + poppler via system call simulation. Store processed files in the environment and add file paths to artifact object under <code>processed_raw_data</code>.</li>
                    <li><strong>Browse Page</strong> (Best for fetching online catalog entries): Use if artifact has a known URL (e.g., CDLI page, ISAC record, or museum page). How: Instructions: “Extract all available metadata fields including CDLI number, provenance, period, language, dimensions, museum location, and any existing photos or transliterations. Return in structured JSON.” Parse the summary and populate <code>external_references</code> and <code>basic_metadata</code>.</li>
                    <li><strong>Web Search</strong> (Supporting tool for discovery): Use when only a vague description is available. How: Query “cuneiform tablet [museum number or description]” to discover source URLs, then feed top results into browse_page.</li>
                </ul>
            </li>

            <li>
                <h3>Stage 2: Digitization & Recognition (Extract Symbols from Raw Form)</h3>
                <p><strong>Description</strong>: Apply OCR/AI to recognize cuneiform signs (glyphs). Turn visual input into digital symbols.</p>
                <p><strong>Artifact Modification</strong>: Add <code>recognized_symbols</code> (list of detected glyphs with bounding boxes, confidence scores, Unicode points), <code>recognition_metadata</code> (model used, accuracy metrics).</p>
                <p><strong>Technical Implementation Details</strong>: Run on the processed images from Stage 1. Use code_execution to load pre-trained models (DeepScribe-style RetinaNet + ResNet) or simulate with open-source alternatives like Kraken OCR. Store bounding boxes as JSON arrays. Version the artifact as v2 in SSoT with recognition results. If accuracy is low (&lt;60%), flag for manual review later.</p>
                <p><strong>Best Tools and Exact Usage</strong>:</p>
                <ul>
                    <li><strong>Code Execution</strong> (Primary tool): Run full recognition pipeline. Example code: load image → apply DeepScribe-like model (or Kraken if torch is available) → output list of signs with coordinates and Unicode. Save results as <code>recognized_symbols.json</code>.</li>
                    <li><strong>Search Images</strong> (Best for reference/validation): Query “standard cuneiform sign chart [sign name]” to retrieve reference images for comparison.</li>
                    <li><strong>Browse Page</strong> (Best for sign lists): Visit CDLI sign list or Oracc sign catalog. Instructions: “Extract mapping rules for signs X-Y to Unicode/ATF values.”</li>
                    <li><strong>Web Search</strong>: Discover latest open-source cuneiform OCR models or datasets.</li>
                </ul>
            </li>

            <li>
                <h3>Stage 3: Transliteration (Phonetic Representation)</h3>
                <p><strong>Description</strong>: Convert recognized symbols to Latin phonetic script using ATF format.</p>
                <p><strong>Artifact Modification</strong>: Add <code>transliteration</code> (ATF string), <code>transliteration_confidence</code>, <code>sign_list_version</code>.</p>
                <p><strong>Technical Implementation Details</strong>: Use rule-based mapping (sign → ATF value) combined with language model post-correction. Store as multi-line ATF text. Validate against known sign lists. Update to version v3 in SSoT.</p>
                <p><strong>Best Tools and Exact Usage</strong>:</p>
                <ul>
                    <li><strong>Code Execution</strong> (Primary): Load recognized_symbols → apply sign-to-ATF dictionary (pre-loaded or fetched) → generate ATF string. Use regex or sympy for pattern validation.</li>
                    <li><strong>Browse Page</strong> (Best for authoritative sign lists): Instructions: “Extract complete sign-to-transliteration mappings for signs in this list: [list of detected signs].”</li>
                    <li><strong>Web Search</strong>: “cuneiform sign list ATF 2024” for updated dictionaries.</li>
                </ul>
            </li>

            <li>
                <h3>Stage 4: Translation (Semantic Meaning)</h3>
                <p><strong>Description</strong>: Translate transliterated text to modern languages (primarily English).</p>
                <p><strong>Artifact Modification</strong>: Add <code>translation</code> (English text), <code>normalized_translation</code>, <code>translation_model</code>, <code>confidence_score</code>.</p>
                <p><strong>Technical Implementation Details</strong>: Call Akkademia-style models or hybrid dictionary + LLM fallback. Post-process for readability. Store parallel versions (literal vs. normalized). Version v4.</p>
                <p><strong>Best Tools and Exact Usage</strong>:</p>
                <ul>
                    <li><strong>Code Execution</strong> (Primary): Load transliteration → run inference with translation model (torch/Hugging Face style) → output English text.</li>
                    <li><strong>Browse Page / Web Search</strong>: Pull lexical entries from CAD, ePSD, or Akkadian dictionaries for ambiguous words.</li>
                </ul>
            </li>

            <li>
                <h3>Stage 5: Annotation & Enrichment (Add Linguistic/Structural Details)</h3>
                <p><strong>Description</strong>: Lemmatize, gloss, and link to related texts via LOD.</p>
                <p><strong>Artifact Modification</strong>: Add <code>lemmas</code>, <code>glosses</code>, <code>linked_entities</code> (RDF-style), <code>cross_references</code>.</p>
                <p><strong>Best Tools and Exact Usage</strong>:</p>
                <ul>
                    <li><strong>Code Execution</strong>: Use networkx/pandas to build entity graphs and lemmatize.</li>
                    <li><strong>Web Search / Browse Page</strong>: Query Oracc or eBL for parallel passages.</li>
                    <li><strong>X Semantic Search / X Keyword Search</strong>: Find scholarly discussions on the text.</li>
                    <li><strong>X Thread Fetch / X User Search</strong>: Identify and fetch threads from known Assyriologists for annotations.</li>
                </ul>
            </li>

            <li>
                <h3>Stage 6: Contextualization (New Layer: Historical and Cultural Enrichment)</h3>
                <p><strong>Description</strong>: Dynamically generate a complete “Grokipedia” article using the predictable taxonomy.</p>
                <p><strong>Artifact Modification</strong>: Add <code>context_article</code> (structured JSON/markdown with all taxonomy sections populated).</p>
                <p><strong>Technical Implementation Details</strong>: Run in parallel sub-tasks per taxonomy category. Aggregate outputs into a single markdown or JSON object. Use code_execution to format and link everything. Version v6.</p>
                <p><strong>Predictable Taxonomy (Balanced Clarity/Rigor)</strong>:</p>
                <table>
                    <thead>
                        <tr>
                            <th>Category (Academic Term)</th>
                            <th>Definition (Rigor)</th>
                            <th>Non-Academic Equivalent</th>
                            <th>Fields to Populate</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Historical Era/Period</td>
                            <td>Chronological phase (e.g., Ur III, 2112–2004 BCE).</td>
                            <td>"Time Period" – like the chapter in history when this happened.</td>
                            <td>Start/end dates, key events, rulers.</td>
                        </tr>
                        <tr>
                            <td>Geographic Provenance</td>
                            <td>Origin/location (e.g., Nippur, modern Iraq).</td>
                            <td>"Where It Came From" – the place it was made or found, like a hometown.</td>
                            <td>Site name, coordinates, modern equivalents.</td>
                        </tr>
                        <tr>
                            <td>People Involved</td>
                            <td>Individuals/entities (e.g., scribe, king mentioned).</td>
                            <td>"Key Players" – the people or groups in the story, like characters in a book.</td>
                            <td>Names, roles, biographies (linked to sources).</td>
                        </tr>
                        <tr>
                            <td>Purpose and Function</td>
                            <td>Intended use (e.g., administrative receipt).</td>
                            <td>"What It Was For" – its job, like a shopping list or love letter.</td>
                            <td>Type (literary/admin), daily life impact.</td>
                        </tr>
                        <tr>
                            <td>Related Events/Cultural Context</td>
                            <td>Broader happenings (e.g., linked to Babylonian exile).</td>
                            <td>"Bigger Picture" – the events or culture around it, like background in a movie.</td>
                            <td>Wars, inventions, societal norms.</td>
                        </tr>
                        <tr>
                            <td>Material and Preservation</td>
                            <td>Physical aspects (e.g., clay, firing state).</td>
                            <td>"How It's Made and Kept" – materials and condition, like recipe and storage tips.</td>
                            <td>Composition, damage, conservation notes.</td>
                        </tr>
                        <tr>
                            <td>Modern Interpretations</td>
                            <td>Scholarly debates/relevance today.</td>
                            <td>"What Experts Say Now" – current views, like book reviews.</td>
                            <td>Theories, pop culture references.</td>
                        </tr>
                    </tbody>
                </table>
                <p><strong>Best Tools and Exact Usage</strong> (Heavy emphasis here):</p>
                <ul>
                    <li><strong>Web Search</strong> (Primary for factual depth): Targeted queries per category (e.g., “Ur III period grain ration economy under Shulgi”).</li>
                    <li><strong>Browse Page</strong> (Primary for depth): Visit Wikipedia, CDLI, ISAC, or academic papers. Instructions: “Summarize [specific category] for artifact [ID] in 300–500 words with sources.”</li>
                    <li><strong>X Semantic Search / X Keyword Search</strong>: Surface recent archaeological discoveries or debates.</li>
                    <li><strong>X Thread Fetch / X User Search</strong>: Pull expert commentary for “Modern Interpretations.”</li>
                    <li><strong>Search Images</strong>: “Map of ancient Nippur”, “Reconstruction of Ur III palace” → embed in context_article.</li>
                    <li><strong>Code Execution</strong>: Compile all tool outputs into structured JSON per taxonomy category.</li>
                </ul>
            </li>

            <li>
                <h3>Stage 7: Output & Archiving (Finalize and Store)</h3>
                <p><strong>Description</strong>: Generate final reports, APIs, and archive the complete artifact.</p>
                <p><strong>Artifact Modification</strong>: Mark <code>status: complete</code>, add <code>final_version</code>, <code>export_formats</code>.</p>
                <p><strong>Best Tools and Exact Usage</strong>:</p>
                <ul>
                    <li><strong>Code Execution</strong> (Primary): Generate PDF/markdown reports, timelines (matplotlib), or JSON-LD exports.</li>
                    <li><strong>Browse Page / Web Search</strong>: Final fact-checking if needed.</li>
                </ul>
            </li>
        </ol>
    </div>

    <div class="section">
        <h2>Implementation Notes</h2>
        <ul>
            <li><strong>Orchestration</strong>: Use Apache Airflow, Prefect, or AWS Step Functions. Each stage is a task that receives the artifact JSON, calls tools, updates the object, and writes the new version to the SSoT.</li>
            <li><strong>SSoT Database</strong>: Neo4j (graph) + MongoDB (document) hybrid for versioned states and rich queries.</li>
            <li><strong>Error Handling & Parallelism</strong>: Stages 5–6 are highly parallelizable. Use retry logic for tool failures.</li>
            <li><strong>Scalability</strong>: Process 1–10 artifacts in parallel; cache frequent lookups (sign lists, dictionaries).</li>
        </ul>
    </div>

    <p>This completes the highly detailed, production-ready pipeline plan. You now have exact tool-to-stage mappings and precise usage instructions for every stage. Let me know if you want sample code snippets, Airflow DAG examples, or database schema next!</p>

</body>
</html>